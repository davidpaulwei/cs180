## Computer Vision Projects

This repository contains my projects for UC Berkeley's course [COMPSCI 180 - Intro to Computer Vision and Computational Photography](https://inst.eecs.berkeley.edu/~cs180/fa24/) on fall 2024 semester. For detailed introduction, visit [website](https://davidpaulwei.github.io/cs180/).  

1. **Project 1: Colorizing the _Prokudin-Gorskii_ Photo Collection** &emsp; [Website](https://davidpaulwei.github.io/cs180/proj1/) | [My Code](https://github.com/davidpaulwei/cs180/tree/main/proj1/code) | [Github Folder](https://github.com/davidpaulwei/cs180/tree/main/proj1)  
   _Prokudin-Gorskii_ photographed the Russian Empire using black-and-white negatives with red, green and blue filters, hoping future technologies could stack the three layers to produce colored image. I took the digitized negatives of _Prokudin-Gorskii_'s work to produce the RGB color image. The original three color layers from _Prokudin-Gorskii_'s work were not accurately aligned, so I designed an alignment algorithm using **Image Pyramid** and **Edge Detection** to preprocess the layers before stacking them together.

2. **Project 2: Fun with Filters and Frequencies** &emsp; [Website](https://davidpaulwei.github.io/cs180/proj2/) | [My Code](https://github.com/davidpaulwei/cs180/tree/main/proj2/code) | [Github Folder](https://github.com/davidpaulwei/cs180/tree/main/proj2)   
   By applying filters and analyzing frequencies, images can be processed and combined in interesting ways. In the first part of this project, edge detection is conducted by applying the **Finite Difference Filter**. **Gaussian Filter** is applied to get rid of the unnecessary wrinkles. Then, images are sharpened by stacking its edges onto itself. The second part of this project consists of two image binding tasks. The first task generates **Hybrid Image** by adding the high frequency of one image to the low frequency of another. Both successful and failing attempts are introduced. The second task **blends images** by applying the **Gaussian Stack** and the **Laplacian Stack**.

3. **Project 3: Face Morphing and Modelling a Photo Collection** &emsp; [Website](https://davidpaulwei.github.io/cs180/proj3/) | [My Code](https://github.com/davidpaulwei/cs180/tree/main/proj3/code) | [Github Folder](https://github.com/davidpaulwei/cs180/tree/main/proj3)   
   In the first part of this project, I morphed two face images using **Affine Transformation**. I obtained 100 correspondences for each of the two faces and computed their average coordinates. **Triangulation** was conducted on the correspondences and for each triangle, **Affine Matrixes** were generated to stretch the triangles from the original image to the Midway image. I used **Cross Dissolve** to bind the color. I furtherly generated a sequence of 51 morphed images using different **Morph Weight** to produce the morphing GIF. In the second part, I computed the mean face of 12 Brazilian faces, and stretched my face into the shape of the mean face. I also computed the mean face of 12 smiling Brazilian faces to add a smile on my grim portrait.

4. **Project 4: Stitching Photo Mosaics** &emsp; [Website](https://davidpaulwei.github.io/cs180/proj4/) | [My Code](https://github.com/davidpaulwei/cs180/tree/main/proj4/code) | [Github Folder](https://github.com/davidpaulwei/cs180/tree/main/proj4)    
   Project 4 consists two parts: <b>Image Warping and Mosaicing</b> (Part A) and <b>Feature Matching for Autostitching</b> (Part B).     
   &emsp; In Part A, I rectified images using <b>Perspective Transform</b>. I manually selected correspondences on the images, and warped themso that their transformed correspondences form a rectangle.I also produced <b>mosaics images</b> by blending pairs of images that overlap with each other. First, I manually matched a few pixels that represent the same corner of an object on the two images. Then, I treated these pixel matches as correspondences, and warped the first image so that after warping, the correspondences on the first image aligns with the correspondences on the second images. In this way, the same objects on the two images would match. Finally, I conducted <b>Alpha Blend</b> on the output mosaic to erase the edge between the 
two images.       
   &emsp; In Part B, I also produced mosaic images, only this time instead of manually matching the pixels, the pixel matches are automatically detected and selected.Corners serve as great symbols of objects on an image, so I used <b>Harris Corner Detector</b> to find the corners on the images, and treat them as interest points. Then, I used <b>Adaptive Non-Maximal Suppression (ANMS)</b> to select a few interest points that are not only high in "corner strength", but also as uniformly distributed in the image as possible. They are the potential correspondences. Later, I matched the potential correspondences using <b>Feature Descriptors</b>. If the best match of a potential correspondence did not score significantly higher than its second-best match, I would abandon this pixel. The matched pixels still may contain error. I found the optimal set of matches using the idea of <b>Random Sample Consensus (RANSAC)</b>. At last, similar to Part A, I used the optimal matches to conduct perspective transform on the first image so that it aligns with the second image, and blended the overlapping region to erase the edge.

Updated on Oct 24, 2024.
